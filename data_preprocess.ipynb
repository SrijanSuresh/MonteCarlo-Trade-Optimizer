{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGeo6dzQ7TVv"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp3EuTfb7UXx"
      },
      "source": [
        "# DATA PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Selln-aC9SKy"
      },
      "source": [
        "### Data Import via Yahoo finance, Alpha Vantage, Tiingo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K08SE_r7zUY"
      },
      "outputs": [],
      "source": [
        "%pip install yahoo_fin\n",
        "%pip install requests_html\n",
        "%pip install alpha-vantage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "Kkz_UFdF7uya"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import yahoo_fin.stock_info as si\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36OwT0reB9Xo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjRhxxZ7Gr-Q"
      },
      "source": [
        "### OHLC, Volume, Corporate Actions data from multiple stickers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB2965Eyv2kd"
      },
      "source": [
        "###### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "juZgreH_v5aI",
        "outputId": "5f10222b-c1db-41b5-c81b-40c6ce3222ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processed Price Data:\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-01-03 00:00:00\",\n        \"max\": \"2023-01-09 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2023-01-04 00:00:00\",\n          \"2023-01-09 00:00:00\",\n          \"2023-01-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4486197157011627,\n        \"min\": 123.5831069946289,\n        \"max\": 128.6541290283203,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          124.90770721435547,\n          128.6541290283203,\n          123.5831069946289\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.158842170706203,\n        \"min\": 126.30150047855705,\n        \"max\": 131.87667022454877,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          127.18127564102066,\n          131.87667022454877,\n          126.30150047855705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.307917254327634,\n        \"min\": 122.74286511723291,\n        \"max\": 128.39712274020837,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          123.64241984503863,\n          128.39712274020837,\n          123.32610067708713\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0454410721086242,\n        \"min\": 124.56170184454875,\n        \"max\": 128.9704583829939,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          125.43161455867813,\n          128.9704583829939,\n          125.66885678017948\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15235853,\n        \"min\": 70790800,\n        \"max\": 112117500,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          89113600,\n          70790800,\n          80962700\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1c504b2a-1eb3-42e3-968a-c8f3ea921d56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ticker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>123.632523</td>\n",
              "      <td>129.395510</td>\n",
              "      <td>122.742865</td>\n",
              "      <td>128.782641</td>\n",
              "      <td>112117500</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>124.907707</td>\n",
              "      <td>127.181276</td>\n",
              "      <td>123.642420</td>\n",
              "      <td>125.431615</td>\n",
              "      <td>89113600</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>123.583107</td>\n",
              "      <td>126.301500</td>\n",
              "      <td>123.326101</td>\n",
              "      <td>125.668857</td>\n",
              "      <td>80962700</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>128.130203</td>\n",
              "      <td>128.792501</td>\n",
              "      <td>123.454572</td>\n",
              "      <td>124.561702</td>\n",
              "      <td>87754700</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-09</td>\n",
              "      <td>128.654129</td>\n",
              "      <td>131.876670</td>\n",
              "      <td>128.397123</td>\n",
              "      <td>128.970458</td>\n",
              "      <td>70790800</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c504b2a-1eb3-42e3-968a-c8f3ea921d56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c504b2a-1eb3-42e3-968a-c8f3ea921d56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c504b2a-1eb3-42e3-968a-c8f3ea921d56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4aeac647-903c-4ed5-8614-3d2b22c84523\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4aeac647-903c-4ed5-8614-3d2b22c84523')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4aeac647-903c-4ed5-8614-3d2b22c84523 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        Date       Close        High         Low        Open     Volume ticker\n",
              "0 2023-01-03  123.632523  129.395510  122.742865  128.782641  112117500   AAPL\n",
              "1 2023-01-04  124.907707  127.181276  123.642420  125.431615   89113600   AAPL\n",
              "2 2023-01-05  123.583107  126.301500  123.326101  125.668857   80962700   AAPL\n",
              "3 2023-01-06  128.130203  128.792501  123.454572  124.561702   87754700   AAPL\n",
              "4 2023-01-09  128.654129  131.876670  128.397123  128.970458   70790800   AAPL"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_price_data(ticker, start_date, end_date):\n",
        "    \"\"\"Get raw OHLCV data and format it into the desired DataFrame structure.\"\"\"\n",
        "    df = yf.download(ticker, start=start_date, end=end_date)\n",
        "    # Reset index to turn Date into a column\n",
        "    df = df.reset_index()\n",
        "    # Flatten the MultiIndex columns (assuming columns have three levels)\n",
        "    # Extract the metric names (second level of MultiIndex)\n",
        "    new_columns = []\n",
        "    for col in df.columns:\n",
        "        if col == 'Date':\n",
        "            new_columns.append('Date')\n",
        "        else:\n",
        "            # Get the second level of the MultiIndex (e.g., 'Close', 'High')\n",
        "            new_columns.append(col[1])\n",
        "    df.columns = new_columns\n",
        "    # Add ticker column\n",
        "    df['ticker'] = ticker\n",
        "    df.columns.values[0] = \"Date\"\n",
        "    df.columns.values[1] = \"Close\"\n",
        "    df.columns.values[2] = \"High\"\n",
        "    df.columns.values[3] = \"Low\"\n",
        "    df.columns.values[4] = \"Open\"\n",
        "    df.columns.values[5] = \"Volume\"\n",
        "\n",
        "    # Reorder columns to the desired order\n",
        "    return df\n",
        "# Test the function\n",
        "test_df = get_price_data(\"AAPL\", \"2023-01-01\", \"2023-01-10\")\n",
        "print(\"\\nProcessed Price Data:\\n\")\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tALErV_g1z50"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHzzc9yR2hcb"
      },
      "source": [
        "#### 1. Calculate Trend of Moving Averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgJVpjCF14sO",
        "outputId": "f37a6a8e-6a3a-4864-8ef6-8d524055916a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trend Indicators:\n",
            "          Date       Close      SMA_20      EMA_20      MACD\n",
            "24 2023-02-07  152.872559  140.194459  141.334063  6.125100\n",
            "25 2023-02-08  150.173950  141.241782  142.175957  6.064972\n",
            "26 2023-02-09  149.135986  142.100793  142.838817  5.865945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n"
          ]
        }
      ],
      "source": [
        "def add_trend_indicators(df):\n",
        "    \"\"\"Add SMA, EMA, MACD (grouped by ticker)\"\"\"\n",
        "    # Ensure we group by ticker if multiple stocks exist\n",
        "    grouped = df.groupby('ticker', group_keys=False)\n",
        "\n",
        "    # Calculate indicators per ticker\n",
        "    def calculate_indicators(group):\n",
        "        # Moving Averages\n",
        "        group['SMA_20'] = group['Close'].rolling(window=20).mean()\n",
        "        group['EMA_20'] = group['Close'].ewm(span=20, adjust=False).mean()\n",
        "\n",
        "        # MACD\n",
        "        exp12 = group['Close'].ewm(span=12, adjust=False).mean()\n",
        "        exp26 = group['Close'].ewm(span=26, adjust=False).mean()\n",
        "        group['MACD'] = exp12 - exp26\n",
        "        group['Signal_Line'] = group['MACD'].ewm(span=9, adjust=False).mean()\n",
        "        return group\n",
        "\n",
        "    return grouped.apply(calculate_indicators)\n",
        "# Get 1 month of data for proper SMA calculation\n",
        "test_df = get_price_data(\"AAPL\", \"2023-01-01\", \"2023-02-10\")\n",
        "trend_df = add_trend_indicators(test_df.copy())\n",
        "\n",
        "# Show last 3 rows where SMA_20 exists\n",
        "print(\"\\nTrend Indicators:\\n\", trend_df[['Date', 'Close', 'SMA_20', 'EMA_20', 'MACD']].tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeT70eeX3Ir7"
      },
      "source": [
        "#### 2. Momentum Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McIy71hv3OlL",
        "outputId": "9bb6a15f-c5c2-460a-f548-734df4c007cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Momentum Indicators:\n",
            "          Date        RSI         %K         %D\n",
            "24 2023-02-07  80.205161  88.437118  84.102776\n",
            "25 2023-02-08  73.888170  76.424960  80.310510\n",
            "26 2023-02-09  69.519540  66.581105  77.147727\n"
          ]
        }
      ],
      "source": [
        "def add_momentum_indicators(df):\n",
        "    \"\"\"Add RSI and Stochastic Oscillator\"\"\"\n",
        "    # RSI\n",
        "    delta = df['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(14).mean()\n",
        "    avg_loss = loss.rolling(14).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Stochastic\n",
        "    low14 = df['Low'].rolling(14).min()\n",
        "    high14 = df['High'].rolling(14).max()\n",
        "    df['%K'] = 100 * ((df['Close'] - low14) / (high14 - low14))\n",
        "    df['%D'] = df['%K'].rolling(3).mean()\n",
        "    return df\n",
        "\n",
        "# Test\n",
        "momentum_df = add_momentum_indicators(trend_df.copy())\n",
        "print(\"\\nMomentum Indicators:\\n\", momentum_df[['Date', 'RSI', '%K', '%D']].tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aHcaWOG3UEF"
      },
      "source": [
        "#### 3. Volatility Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9B--QGG3xl5",
        "outputId": "5af12938-dadd-4b59-de82-cb1906f76536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Volatility Indicators:\n",
            "          Date  Upper_Band  Lower_Band       ATR\n",
            "24 2023-02-07  154.518024  125.870893  4.158079\n",
            "25 2023-02-08  155.248620  127.234943  4.228686\n",
            "26 2023-02-09  155.813943  128.387643  4.236453\n"
          ]
        }
      ],
      "source": [
        "def add_volatility_indicators(df):\n",
        "    \"\"\"Add Bollinger Bands and ATR\"\"\"\n",
        "    # Bollinger Bands\n",
        "    df['Middle_Band'] = df['Close'].rolling(20).mean()\n",
        "    df['Upper_Band'] = df['Middle_Band'] + 2*df['Close'].rolling(20).std()\n",
        "    df['Lower_Band'] = df['Middle_Band'] - 2*df['Close'].rolling(20).std()\n",
        "\n",
        "    # ATR\n",
        "    high_low = df['High'] - df['Low']\n",
        "    high_close = np.abs(df['High'] - df['Close'].shift())\n",
        "    low_close = np.abs(df['Low'] - df['Close'].shift())\n",
        "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "    df['ATR'] = tr.rolling(14).mean()\n",
        "    return df\n",
        "\n",
        "# Test\n",
        "volatility_df = add_volatility_indicators(momentum_df.copy())\n",
        "print(\"\\nVolatility Indicators:\\n\", volatility_df[['Date', 'Upper_Band', 'Lower_Band', 'ATR']].tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyeMV19E3WUU"
      },
      "source": [
        "#### 4. Volume Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKmB9B0g3_B3",
        "outputId": "b047203b-34c1-4c67-8947-29ccbd8e38ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Volume Indicators:\n",
            "          Date       CMF  Volume_ROC\n",
            "24 2023-02-07  0.423644   19.273730\n",
            "25 2023-02-08  0.371651  -23.045968\n",
            "26 2023-02-09  0.300219  -12.652819\n"
          ]
        }
      ],
      "source": [
        "def add_volume_indicators(df):\n",
        "    \"\"\"Add CMF and Volume ROC\"\"\"\n",
        "    # Chaikin Money Flow\n",
        "    mfm = ((df['Close'] - df['Low']) - (df['High'] - df['Close'])) / (df['High'] - df['Low'])\n",
        "    mfm = mfm.replace([np.inf, -np.inf], 0)\n",
        "    mfv = mfm * df['Volume']\n",
        "    df['CMF'] = mfv.rolling(20).sum() / df['Volume'].rolling(20).sum()\n",
        "\n",
        "    # Volume ROC\n",
        "    df['Volume_ROC'] = df['Volume'].pct_change(1) * 100\n",
        "    return df\n",
        "\n",
        "# Test\n",
        "volume_df = add_volume_indicators(volatility_df.copy())\n",
        "print(\"\\nVolume Indicators:\\n\", volume_df[['Date', 'CMF', 'Volume_ROC']].tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdt74Jza3Z2O"
      },
      "source": [
        "#### 5. Returns & Risk Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqfpT6qt3_nj",
        "outputId": "8603f664-8ae7-4875-f2c3-abaa2ec04059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Risk Metrics:\n",
            "          Date  Log_Returns  Rolling_Vol_21D\n",
            "24 2023-02-07     0.019062         0.217971\n",
            "25 2023-02-08    -0.017810         0.235900\n",
            "26 2023-02-09    -0.006936         0.240916\n"
          ]
        }
      ],
      "source": [
        "def add_risk_metrics(df, risk_free_rate=0.0135):\n",
        "    \"\"\"Add returns and risk metrics\"\"\"\n",
        "    # Returns\n",
        "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "    df['Rolling_Vol_21D'] = df['Log_Returns'].rolling(21).std() * np.sqrt(252)\n",
        "\n",
        "    # Drawdown\n",
        "    cumulative_returns = (1 + df['Log_Returns']).cumprod()\n",
        "    peak = cumulative_returns.expanding().max()\n",
        "    df['Drawdown'] = (peak - cumulative_returns) / peak\n",
        "\n",
        "    # Sharpe Ratio\n",
        "    df['Sharpe'] = (df['Log_Returns'].mean() - risk_free_rate/252) / df['Log_Returns'].std()\n",
        "    return df\n",
        "\n",
        "# Test\n",
        "final_df = add_risk_metrics(volume_df.copy())\n",
        "print(\"\\nRisk Metrics:\\n\", final_df[['Date', 'Log_Returns', 'Rolling_Vol_21D']].tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOZZCqSh3bLa"
      },
      "source": [
        "#### 6. Corporate Actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Yh9S673_-d",
        "outputId": "c03c60e6-5277-4fbc-92fd-fb0d21710744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Corporate Actions: {'Dividends': 2.5825, 'Splits': 1}\n"
          ]
        }
      ],
      "source": [
        "def get_corporate_actions(ticker, start_date, end_date):\n",
        "    \"\"\"Get dividends and splits\"\"\"\n",
        "    yf_ticker = yf.Ticker(ticker)\n",
        "    return {\n",
        "        'Dividends': yf_ticker.dividends.loc[start_date:end_date].sum(),\n",
        "        'Splits': yf_ticker.splits.loc[start_date:end_date].count()\n",
        "    }\n",
        "\n",
        "# Test\n",
        "print(\"\\nCorporate Actions:\", get_corporate_actions(\"AAPL\", \"2020-01-01\", \"2023-01-01\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTMyUAN93cX2"
      },
      "source": [
        "### Incorporate all Features and return combined Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xh1A6XEh9iCL",
        "outputId": "28e480dd-adbd-468c-b584-647ba0489b60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Dataset Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'ticker', 'SMA_20', 'EMA_20', 'MACD', 'Signal_Line', 'RSI', '%K', '%D', 'Middle_Band', 'Upper_Band', 'Lower_Band', 'ATR', 'CMF', 'Volume_ROC', 'Log_Returns', 'Rolling_Vol_21D', 'Drawdown', 'Sharpe', 'Dividends', 'Splits']\n",
            "\n",
            "Sample Data:\n",
            "          Date      Close       High        Low       Open     Volume ticker  \\\n",
            "21 2020-02-03  74.727974  75.897335  73.168820  73.672395  173788400   AAPL   \n",
            "22 2020-02-04  77.194984  77.386249  75.931199  76.337933  136616400   AAPL   \n",
            "23 2020-02-05  77.824463  78.625828  77.219202  78.325613  118826800   AAPL   \n",
            "24 2020-02-06  78.734779  78.737203  77.536367  78.095628  105425600   AAPL   \n",
            "25 2020-02-07  77.664574  78.482401  77.171936  78.232442  117684000   AAPL   \n",
            "\n",
            "       SMA_20     EMA_20      MACD  ...  Lower_Band       ATR       CMF  \\\n",
            "21  75.792247  75.721162  0.764573  ...   72.320495  1.748168  0.124594   \n",
            "22  76.022851  75.861526  0.790719  ...   72.848739  1.844662  0.119425   \n",
            "23  76.301997  76.048472  0.852408  ...   73.578021  1.843970  0.131048   \n",
            "24  76.568554  76.304311  0.963643  ...   73.999826  1.854345  0.138747   \n",
            "25  76.703643  76.433860  0.954439  ...   74.207330  1.901300  0.092738   \n",
            "\n",
            "    Volume_ROC  Log_Returns  Rolling_Vol_21D  Drawdown    Sharpe  Dividends  \\\n",
            "21  -12.926603    -0.002750         0.275597  0.049357  0.030097     2.5825   \n",
            "22  -21.389230     0.032480         0.292555  0.018481  0.030097     2.5825   \n",
            "23  -13.021570     0.008121         0.292593  0.010509  0.030097     2.5825   \n",
            "24  -11.277927     0.011629         0.292415  0.000000  0.030097     2.5825   \n",
            "25   11.627536    -0.013686         0.295284  0.013686  0.030097     2.5825   \n",
            "\n",
            "    Splits  \n",
            "21       1  \n",
            "22       1  \n",
            "23       1  \n",
            "24       1  \n",
            "25       1  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "<ipython-input-184-16f7ab0c4e8e>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return grouped.apply(calculate_indicators)\n"
          ]
        }
      ],
      "source": [
        "from concurrent.futures import process\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "dow_list = si.tickers_dow()\n",
        "def build_full_dataset(tickers, start_date, end_date):\n",
        "    final_data = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            # Core data\n",
        "            df = get_price_data(ticker, start_date, end_date)\n",
        "\n",
        "            # Add features\n",
        "            df = add_trend_indicators(df)\n",
        "            df = add_momentum_indicators(df)\n",
        "            df = add_volatility_indicators(df)\n",
        "            df = add_volume_indicators(df)\n",
        "            df = add_risk_metrics(df)\n",
        "\n",
        "            # Add corporate actions\n",
        "            actions = get_corporate_actions(ticker, start_date, end_date)\n",
        "            df['Dividends'] = actions['Dividends']\n",
        "            df['Splits'] = actions['Splits']\n",
        "\n",
        "            final_data.append(df)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipped {ticker}: {str(e)}\")\n",
        "\n",
        "    return pd.concat(final_data, ignore_index=True).dropna()\n",
        "\n",
        "full_dataset = build_full_dataset(dow_list[:3], \"2020-01-01\", \"2023-01-01\")  # Test with first 3 tickers\n",
        "print(\"\\nFinal Dataset Columns:\", full_dataset.columns.tolist())\n",
        "print(\"\\nSample Data:\\n\", full_dataset.head())\n",
        "\n",
        "processed_df = build_full_dataset(dow_list, start_date, end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXeNzyTN6JVn"
      },
      "source": [
        "## Normalize/Standardize for NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "qVSFf4m06s-p"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2vgrX1E6Ndi"
      },
      "source": [
        "#### a. Min-Max Scaling (0-1 range):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "uCpCQMNo6wAa"
      },
      "outputs": [],
      "source": [
        "def scale_features_min_max(df):\n",
        "    \"\"\"Normalize feature columns using Min-Max scaling\"\"\"\n",
        "    # Columns to exclude from scaling\n",
        "    non_feature_cols = ['Date', 'ticker']\n",
        "    feature_cols = [col for col in df.columns if col not in non_feature_cols]\n",
        "\n",
        "    # Initialize scaler and fit to training data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_values = scaler.fit_transform(df[feature_cols])\n",
        "\n",
        "    # Rebuild DataFrame\n",
        "    scaled_df = pd.DataFrame(scaled_values, columns=feature_cols)\n",
        "    return pd.concat([df[non_feature_cols], scaled_df], axis=1), scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeurJy7f6Pso"
      },
      "source": [
        "#### b. Standardization (Z-score):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "xP1epixW642Y"
      },
      "outputs": [],
      "source": [
        "def scale_features_z_score(df, scaler=None):\n",
        "    \"\"\"Z-score normalization while preserving market data\"\"\"\n",
        "    # Columns to preserve unchanged\n",
        "    preserved = [\n",
        "        'Date', 'ticker', 'Close', 'High', 'Low', 'Open', 'Volume',\n",
        "        'Log_Returns', 'Dividends', 'Splits', \n",
        "        'SMA_20', 'EMA_20', 'Middle_Band', 'Upper_Band', 'Lower_Band',  # Price-based indicators\n",
        "        'ATR', 'Rolling_Vol_21D', 'Drawdown', 'Sharpe'  # Risk metrics\n",
        "    ]\n",
        "    \n",
        "    # Columns to scale (technical indicators)\n",
        "    scale_cols = [c for c in df.columns if c not in preserved]\n",
        "    \n",
        "    # Separate data\n",
        "    metadata = df[preserved].copy()\n",
        "    features = df[scale_cols]\n",
        "    \n",
        "    # Initialize/reuse scaler\n",
        "    if scaler is None:\n",
        "        scaler = StandardScaler()\n",
        "        scaled_features = scaler.fit_transform(features)\n",
        "    else:\n",
        "        scaled_features = scaler.transform(features)\n",
        "    \n",
        "    # Rebuild DataFrame\n",
        "    scaled_df = pd.DataFrame(scaled_features, \n",
        "                            columns=scale_cols, \n",
        "                            index=df.index)\n",
        "    \n",
        "    return pd.concat([metadata, scaled_df], axis=1), scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jc2npG26RES"
      },
      "source": [
        "## Chronological Data Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "_VsLkNZp7MmA"
      },
      "outputs": [],
      "source": [
        "# Modified time series split to maintain temporal structure\n",
        "def time_series_split(df, train_ratio=0.7, test_ratio=0.2):\n",
        "    \"\"\"Split data sequentially while maintaining time order\"\"\"\n",
        "    df = df.sort_values('Date').reset_index(drop=True)\n",
        "    n = len(df)\n",
        "    \n",
        "    train_end = int(n * train_ratio)\n",
        "    test_end = train_end + int(n * test_ratio)\n",
        "    \n",
        "    return (\n",
        "        df.iloc[:train_end],  # Train\n",
        "        df.iloc[train_end:test_end],  # Test\n",
        "        df.iloc[test_end:]  # Black swan (remaining data)\n",
        "    )\n",
        "\n",
        "# Proper usage flow:\n",
        "# 1. Split first to prevent leakage\n",
        "train_raw, test_raw, black_swan_raw = time_series_split(processed_df)\n",
        "\n",
        "# 2. Scale using training data statistics\n",
        "train_scaled, scaler = scale_features_z_score(train_raw)\n",
        "test_scaled, _ = scale_features_z_score(test_raw, scaler)\n",
        "black_swan_scaled, _ = scale_features_z_score(black_swan_raw, scaler)\n",
        "\n",
        "# 3. Verify critical columns remain unscaled\n",
        "print(train_scaled[['Date', 'ticker', 'Close', 'Log_Returns']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3bYDJtc6cCx"
      },
      "source": [
        "## Full Pipeline Integration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxvQmCwkB-JJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X0atf5B7PO7",
        "outputId": "ca22f261-bda4-45bb-e7a7-171270be2716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 26901\n",
            "Test samples: 7686\n",
            "Black swan samples: 3843\n"
          ]
        }
      ],
      "source": [
        "# 1. Split first to prevent leakage\n",
        "train_raw, test_raw, black_swan_raw = time_series_split(processed_df)\n",
        "\n",
        "# 2. Scale using training data statistics\n",
        "train_scaled, scaler = scale_features_z_score(train_raw)\n",
        "test_scaled, _ = scale_features_z_score(test_raw, scaler)\n",
        "black_swan_scaled, _ = scale_features_z_score(black_swan_raw, scaler)\n",
        "\n",
        "# 3. Verify critical columns remain unscaled\n",
        "print(train_scaled[['Date', 'ticker', 'Close', 'Log_Returns']].head())\n",
        "\n",
        "# Final formatted datasets\n",
        "print(f\"Training set shape: {train_scaled.shape}\")\n",
        "print(f\"Test set shape: {test_scaled.shape}\")\n",
        "print(f\"Black swan reserve shape: {black_swan_scaled.shape}\")\n",
        "\n",
        "# Verify columns\n",
        "print(\"\\nSample scaled training data:\")\n",
        "print(train_scaled[['Date', 'ticker', 'Close', 'SMA_20']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS9r6n_wB-7O"
      },
      "source": [
        "## Export Data as CSV for ML/DL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLMnvcrJCBrn",
        "outputId": "37dfc117-a1cf-4207-f789-b42793bfa12a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved files:\n",
            "['test_scaled.csv', 'black_swan_scaled.csv', 'train_scaled.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create directory if needed\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Save scaled datasets\n",
        "train_scaled.to_csv('data/train_scaled.csv', index=False)\n",
        "test_scaled.to_csv('data/test_scaled.csv', index=False)\n",
        "black_swan_scaled.to_csv('data/black_swan_scaled.csv', index=False)\n",
        "\n",
        "# Optional: Save scaler for new data transformations\n",
        "# from joblib import dump\n",
        "# dump(scaler, 'data/scaler.joblib')\n",
        "\n",
        "print(\"Saved files:\")\n",
        "print(os.listdir('data'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QjRhxxZ7Gr-Q",
        "tALErV_g1z50",
        "bXeNzyTN6JVn",
        "l2vgrX1E6Ndi",
        "1Jc2npG26RES"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
